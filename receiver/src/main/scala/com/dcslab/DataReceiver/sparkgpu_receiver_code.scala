package com.dcslab.DataReceiver

import org.apache.spark.{SparkConf,SparkContext}
import org.apache.spark.streaming.{Seconds,Time, StreamingContext}
import org.apache.spark.storage.StorageLevel
import java.nio.charset.Charset
import jcuda.runtime.JCuda
import com.ibm.gpuenabler._
import com.ibm.gpuenabler.CUDAFunction
import com.ibm.gpuenabler.CUDARDDImplicits._

object SparkGPUDataReceiveScala {
  def main(args: Array[String]) {
    if (args.length < 2) {
      System.err.println("Usage: SparkGPUDataReceiveScala <hostname> <port>")
        System.exit(1)
    }
    val masterURL = if (args.length > 0) args(0) else "local[*]"
    // Create the context with a 1 second batch size
    val sparkConf = new SparkConf().setAppName("SparkGPUDataReceiveScala")
    val ssc = new StreamingContext(sparkConf, Seconds(1))

      val ptxURL = getClass.getResource("/DataReceiveScala.ptx")
      try{
        val longMapFunction = new CUDAFunction(
            "long_map_errcount",
            Array("this"),
            Array("this"),
            ptxURL)


          val intMapFunction = new CUDAFunction(
              "int_map_errcount",
              Array("this"),
              Array("this"),
              ptxURL)

          val dimensions = (size: Long, stage: Int) => stage match {
            case 0 => (64, 256)
              case 1 => (1, 1)
          }
        val reduceFunction = new CUDAFunction(
            "sum",
            Array("this"),
            Array("this"),
            ptxURL,
            Seq(),
            Some((size: Long) => 2),
            Some(dimensions))
      }
    catch {
      case e => {
        e.printStackTrace()
      }
    }
    //StreamingExamples.setStreamingLogLevels()


      // Create a socket stream on target ip:port and count the
      // words in input stream of \n delimited text (eg. generated by 'nc')
      // Note that no duplication in storage level only for running locally.
      // Replication necessary in distributed scenario for fault tolerance.
      val lines = ssc.socketTextStream(args(0), args(1).toInt, StorageLevel.MEMORY_AND_DISK_SER)
      val list=lines.flatMap(x=>x.split(" ")).map(x=>x.split(":"))
      val longs = list.filter(x=>x(0).contains("long"))
      val ints = list.filter(x=>x(0).contains("int"))

      ints.print()

      ssc.start()
      ssc.awaitTermination()
  }
}
// scalastyle:on println//
