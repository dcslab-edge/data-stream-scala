//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-23162084
// Cuda compilation tools, release 9.0, V9.0.252
// Based on LLVM 3.4svn
//

.version 6.0
.target sm_30
.address_size 64

	// .globl	long_map_errcount
.extern .func __assertfail
(
	.param .b64 __assertfail_param_0,
	.param .b64 __assertfail_param_1,
	.param .b32 __assertfail_param_2,
	.param .b64 __assertfail_param_3,
	.param .b64 __assertfail_param_4
)
;
.global .align 16 .b8 __unnamed_1[44] = {118, 111, 105, 100, 32, 115, 117, 109, 40, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 41, 0};
.global .align 16 .b8 __unnamed_2[41] = {118, 111, 105, 100, 32, 115, 117, 109, 108, 40, 105, 110, 116, 44, 32, 108, 111, 110, 103, 32, 42, 44, 32, 108, 111, 110, 103, 32, 42, 44, 32, 105, 110, 116, 44, 32, 105, 110, 116, 41, 0};
.global .align 16 .b8 $str[31] = {106, 117, 109, 112, 32, 61, 61, 32, 98, 108, 111, 99, 107, 68, 105, 109, 46, 120, 32, 42, 32, 103, 114, 105, 100, 68, 105, 109, 46, 120, 0};
.global .align 16 .b8 $str1[39] = {115, 114, 99, 47, 109, 97, 105, 110, 47, 114, 101, 115, 111, 117, 114, 99, 101, 115, 47, 68, 97, 116, 97, 82, 101, 99, 101, 105, 118, 101, 83, 99, 97, 108, 97, 46, 99, 117, 0};

.visible .entry long_map_errcount(
	.param .u32 long_map_errcount_param_0,
	.param .u64 long_map_errcount_param_1,
	.param .u64 long_map_errcount_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r2, [long_map_errcount_param_0];
	ld.param.u64 	%rd2, [long_map_errcount_param_1];
	ld.param.u64 	%rd3, [long_map_errcount_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB0_4;

	cvta.to.global.u64 	%rd4, %rd3;
	cvta.to.global.u64 	%rd5, %rd2;
	mul.wide.s32 	%rd6, %r1, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u64 	%rd8, [%rd7];
	setp.gt.s64	%p2, %rd8, 10000;
	add.s64 	%rd1, %rd4, %rd6;
	@%p2 bra 	BB0_3;
	bra.uni 	BB0_2;

BB0_3:
	mov.u64 	%rd10, 0;
	st.global.u64 	[%rd1], %rd10;
	bra.uni 	BB0_4;

BB0_2:
	mov.u64 	%rd9, 1;
	st.global.u64 	[%rd1], %rd9;

BB0_4:
	ret;
}

	// .globl	int_map_errcount
.visible .entry int_map_errcount(
	.param .u32 int_map_errcount_param_0,
	.param .u64 int_map_errcount_param_1,
	.param .u64 int_map_errcount_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r2, [int_map_errcount_param_0];
	ld.param.u64 	%rd2, [int_map_errcount_param_1];
	ld.param.u64 	%rd3, [int_map_errcount_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB1_4;

	cvta.to.global.u64 	%rd4, %rd3;
	cvta.to.global.u64 	%rd5, %rd2;
	mul.wide.s32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u32 	%r6, [%rd7];
	add.s32 	%r7, %r6, -50;
	setp.lt.u32	%p2, %r7, 30;
	add.s64 	%rd1, %rd4, %rd6;
	@%p2 bra 	BB1_3;
	bra.uni 	BB1_2;

BB1_3:
	mov.u32 	%r9, 0;
	st.global.u32 	[%rd1], %r9;
	bra.uni 	BB1_4;

BB1_2:
	mov.u32 	%r8, 1;
	st.global.u32 	[%rd1], %r8;

BB1_4:
	ret;
}

	// .globl	sum
.visible .entry sum(
	.param .u64 sum_param_0,
	.param .u64 sum_param_1,
	.param .u64 sum_param_2,
	.param .u64 sum_param_3,
	.param .u64 sum_param_4
)
{
	.reg .pred 	%p<18>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<78>;


	ld.param.u64 	%rd33, [sum_param_0];
	ld.param.u64 	%rd34, [sum_param_1];
	ld.param.u64 	%rd32, [sum_param_2];
	ld.param.u64 	%rd35, [sum_param_3];
	cvta.to.global.u64 	%rd1, %rd34;
	cvta.to.global.u64 	%rd2, %rd33;
	mov.u32 	%r23, %tid.x;
	cvt.u64.u32	%rd3, %r23;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mul.wide.u32 	%rd4, %r1, %r24;
	add.s64 	%rd5, %rd4, %rd3;
	cvta.to.global.u64 	%rd36, %rd35;
	ld.global.u32 	%r25, [%rd36];
	setp.eq.s32	%p1, %r25, 0;
	@%p1 bra 	BB2_13;

	setp.ne.s64	%p2, %rd5, 0;
	@%p2 bra 	BB2_27;

	ld.global.s32 	%rd37, [%rd2];
	setp.lt.s64	%p3, %rd37, 16384;
	selp.b64	%rd6, %rd37, 16384, %p3;
	mov.u32 	%r59, 0;
	setp.lt.s64	%p4, %rd6, 1;
	@%p4 bra 	BB2_12;

	and.b64  	%rd41, %rd6, 3;
	mov.u32 	%r59, 0;
	mov.u64 	%rd70, 0;
	setp.eq.s64	%p5, %rd41, 0;
	@%p5 bra 	BB2_9;

	setp.eq.s64	%p6, %rd41, 1;
	@%p6 bra 	BB2_8;

	setp.eq.s64	%p7, %rd41, 2;
	@%p7 bra 	BB2_7;

	ld.global.u32 	%r59, [%rd1];
	mov.u64 	%rd70, 1;

BB2_7:
	shl.b64 	%rd43, %rd70, 2;
	add.s64 	%rd44, %rd1, %rd43;
	ld.global.u32 	%r30, [%rd44];
	add.s32 	%r59, %r30, %r59;
	add.s64 	%rd70, %rd70, 1;

BB2_8:
	shl.b64 	%rd45, %rd70, 2;
	add.s64 	%rd46, %rd1, %rd45;
	ld.global.u32 	%r31, [%rd46];
	add.s32 	%r59, %r31, %r59;
	add.s64 	%rd70, %rd70, 1;

BB2_9:
	setp.lt.u64	%p8, %rd6, 4;
	@%p8 bra 	BB2_12;

	shl.b64 	%rd47, %rd70, 2;
	add.s64 	%rd71, %rd1, %rd47;

BB2_11:
	ld.global.u32 	%r32, [%rd71];
	add.s32 	%r33, %r32, %r59;
	ld.global.u32 	%r34, [%rd71+4];
	add.s32 	%r35, %r34, %r33;
	ld.global.u32 	%r36, [%rd71+8];
	add.s32 	%r37, %r36, %r35;
	ld.global.u32 	%r38, [%rd71+12];
	add.s32 	%r59, %r38, %r37;
	add.s64 	%rd71, %rd71, 16;
	add.s64 	%rd70, %rd70, 4;
	setp.lt.s64	%p9, %rd70, %rd6;
	@%p9 bra 	BB2_11;

BB2_12:
	cvta.to.global.u64 	%rd48, %rd32;
	st.global.u32 	[%rd48], %r59;
	bra.uni 	BB2_27;

BB2_13:
	ld.global.u32 	%r60, [%rd2];
	cvt.s64.s32	%rd49, %r60;
	setp.ge.s64	%p10, %rd5, %rd49;
	@%p10 bra 	BB2_27;

	mov.u32 	%r39, %nctaid.x;
	mul.lo.s32 	%r40, %r39, %r1;
	setp.eq.s32	%p11, %r40, 16384;
	@%p11 bra 	BB2_16;

	mov.u64 	%rd50, $str;
	cvta.global.u64 	%rd51, %rd50;
	mov.u64 	%rd52, $str1;
	cvta.global.u64 	%rd53, %rd52;
	mov.u64 	%rd54, __unnamed_1;
	cvta.global.u64 	%rd55, %rd54;
	mov.u32 	%r41, 39;
	mov.u64 	%rd56, 1;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd51;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd53;
	.param .b32 param2;
	st.param.b32	[param2+0], %r41;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd55;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd56;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 0
	ld.global.u32 	%r60, [%rd2];

BB2_16:
	cvt.s64.s32	%rd17, %r60;
	shl.b64 	%rd57, %rd5, 2;
	add.s64 	%rd18, %rd1, %rd57;
	mov.u32 	%r65, 0;
	setp.ge.s64	%p12, %rd5, %rd17;
	@%p12 bra 	BB2_26;

	add.s64 	%rd19, %rd5, 16384;
	max.s64 	%rd58, %rd19, %rd17;
	add.s64 	%rd59, %rd58, -1;
	sub.s64 	%rd60, %rd59, %rd4;
	sub.s64 	%rd61, %rd60, %rd3;
	shr.u64 	%rd62, %rd61, 14;
	add.s64 	%rd20, %rd62, 1;
	and.b64  	%rd21, %rd20, 3;
	setp.eq.s64	%p13, %rd21, 0;
	mov.u32 	%r65, 0;
	@%p13 bra 	BB2_23;

	setp.eq.s64	%p14, %rd21, 1;
	mov.u32 	%r62, 0;
	@%p14 bra 	BB2_22;

	setp.eq.s64	%p15, %rd21, 2;
	mov.u32 	%r61, 0;
	@%p15 bra 	BB2_21;

	ld.global.u32 	%r61, [%rd18];
	mov.u64 	%rd5, %rd19;

BB2_21:
	shl.b64 	%rd63, %rd5, 2;
	add.s64 	%rd64, %rd1, %rd63;
	ld.global.u32 	%r46, [%rd64];
	add.s32 	%r62, %r46, %r61;
	add.s64 	%rd5, %rd5, 16384;

BB2_22:
	shl.b64 	%rd65, %rd5, 2;
	add.s64 	%rd66, %rd1, %rd65;
	ld.global.u32 	%r47, [%rd66];
	add.s32 	%r65, %r47, %r62;
	add.s64 	%rd5, %rd5, 16384;

BB2_23:
	setp.lt.u64	%p16, %rd20, 4;
	@%p16 bra 	BB2_26;

	shl.b64 	%rd67, %rd5, 2;
	add.s64 	%rd76, %rd1, %rd67;

BB2_25:
	ld.global.u32 	%r48, [%rd76];
	add.s32 	%r49, %r48, %r65;
	ld.global.u32 	%r50, [%rd76+65536];
	add.s32 	%r51, %r50, %r49;
	ld.global.u32 	%r52, [%rd76+131072];
	add.s32 	%r53, %r52, %r51;
	ld.global.u32 	%r54, [%rd76+196608];
	add.s32 	%r65, %r54, %r53;
	add.s64 	%rd76, %rd76, 262144;
	add.s64 	%rd5, %rd5, 65536;
	setp.lt.s64	%p17, %rd5, %rd17;
	@%p17 bra 	BB2_25;

BB2_26:
	st.global.u32 	[%rd18], %r65;

BB2_27:
	ret;
}

	// .globl	suml
.visible .entry suml(
	.param .u32 suml_param_0,
	.param .u64 suml_param_1,
	.param .u64 suml_param_2,
	.param .u32 suml_param_3,
	.param .u32 suml_param_4
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<125>;


	ld.param.u32 	%r2, [suml_param_0];
	ld.param.u64 	%rd50, [suml_param_1];
	ld.param.u64 	%rd49, [suml_param_2];
	ld.param.u32 	%r3, [suml_param_3];
	cvta.to.global.u64 	%rd1, %rd50;
	mov.u32 	%r4, %tid.x;
	cvt.u64.u32	%rd2, %r4;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mul.wide.u32 	%rd3, %r1, %r5;
	add.s64 	%rd4, %rd3, %rd2;
	setp.eq.s32	%p1, %r3, 0;
	@%p1 bra 	BB3_15;

	setp.ne.s64	%p2, %rd4, 0;
	@%p2 bra 	BB3_28;

	setp.lt.s32	%p3, %r2, 16384;
	cvt.s64.s32	%rd52, %r2;
	selp.b64	%rd5, %rd52, 16384, %p3;
	mov.u64 	%rd114, 0;
	setp.lt.s64	%p4, %rd5, 1;
	@%p4 bra 	BB3_14;

	and.b64  	%rd59, %rd5, 3;
	mov.u64 	%rd109, 0;
	setp.eq.s64	%p5, %rd59, 0;
	@%p5 bra 	BB3_4;

	setp.eq.s64	%p6, %rd59, 1;
	@%p6 bra 	BB3_6;
	bra.uni 	BB3_7;

BB3_6:
	mov.u64 	%rd108, %rd109;
	bra.uni 	BB3_10;

BB3_15:
	cvt.s64.s32	%rd25, %r2;
	setp.ge.s64	%p10, %rd4, %rd25;
	@%p10 bra 	BB3_28;

	mov.u32 	%r6, %nctaid.x;
	mul.lo.s32 	%r7, %r6, %r1;
	setp.eq.s32	%p11, %r7, 16384;
	@%p11 bra 	BB3_18;

	mov.u64 	%rd76, $str;
	cvta.global.u64 	%rd77, %rd76;
	mov.u64 	%rd78, $str1;
	cvta.global.u64 	%rd79, %rd78;
	mov.u64 	%rd80, __unnamed_2;
	cvta.global.u64 	%rd81, %rd80;
	mov.u32 	%r8, 64;
	mov.u64 	%rd82, 1;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd77;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd79;
	.param .b32 param2;
	st.param.b32	[param2+0], %r8;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd81;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd82;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 1

BB3_18:
	add.s64 	%rd84, %rd25, -1;
	sub.s64 	%rd85, %rd84, %rd3;
	sub.s64 	%rd86, %rd85, %rd2;
	shr.u64 	%rd87, %rd86, 14;
	add.s64 	%rd26, %rd87, 1;
	and.b64  	%rd27, %rd26, 3;
	setp.eq.s64	%p12, %rd27, 0;
	shl.b64 	%rd88, %rd4, 3;
	add.s64 	%rd28, %rd1, %rd88;
	mov.u64 	%rd124, 0;
	@%p12 bra 	BB3_24;

	setp.eq.s64	%p13, %rd27, 1;
	mov.u64 	%rd118, 0;
	@%p13 bra 	BB3_23;

	setp.eq.s64	%p14, %rd27, 2;
	mov.u64 	%rd116, 0;
	@%p14 bra 	BB3_22;

	ld.global.u64 	%rd116, [%rd28];
	add.s64 	%rd4, %rd4, 16384;

BB3_22:
	shl.b64 	%rd91, %rd4, 3;
	add.s64 	%rd92, %rd1, %rd91;
	ld.global.u64 	%rd93, [%rd92];
	add.s64 	%rd118, %rd93, %rd116;
	add.s64 	%rd4, %rd4, 16384;

BB3_23:
	shl.b64 	%rd94, %rd4, 3;
	add.s64 	%rd95, %rd1, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	add.s64 	%rd124, %rd96, %rd118;
	add.s64 	%rd4, %rd4, 16384;

BB3_24:
	setp.lt.u64	%p15, %rd26, 4;
	@%p15 bra 	BB3_27;

	shl.b64 	%rd97, %rd4, 3;
	add.s64 	%rd121, %rd1, %rd97;

BB3_26:
	ld.global.u64 	%rd98, [%rd121];
	add.s64 	%rd99, %rd98, %rd124;
	ld.global.u64 	%rd100, [%rd121+131072];
	add.s64 	%rd101, %rd100, %rd99;
	ld.global.u64 	%rd102, [%rd121+262144];
	add.s64 	%rd103, %rd102, %rd101;
	ld.global.u64 	%rd104, [%rd121+393216];
	add.s64 	%rd124, %rd104, %rd103;
	add.s64 	%rd121, %rd121, 524288;
	add.s64 	%rd4, %rd4, 65536;
	setp.lt.s64	%p16, %rd4, %rd25;
	@%p16 bra 	BB3_26;

BB3_27:
	st.global.u64 	[%rd28], %rd124;
	bra.uni 	BB3_28;

BB3_4:
	mov.u64 	%rd114, %rd109;
	bra.uni 	BB3_11;

BB3_7:
	setp.eq.s64	%p7, %rd59, 2;
	mov.u64 	%rd106, %rd109;
	@%p7 bra 	BB3_9;

	ld.global.u64 	%rd106, [%rd1];
	mov.u64 	%rd109, 1;

BB3_9:
	shl.b64 	%rd61, %rd109, 3;
	add.s64 	%rd62, %rd1, %rd61;
	ld.global.u64 	%rd63, [%rd62];
	add.s64 	%rd108, %rd63, %rd106;
	add.s64 	%rd109, %rd109, 1;

BB3_10:
	shl.b64 	%rd64, %rd109, 3;
	add.s64 	%rd65, %rd1, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	add.s64 	%rd114, %rd66, %rd108;
	add.s64 	%rd109, %rd109, 1;

BB3_11:
	setp.lt.u64	%p8, %rd5, 4;
	@%p8 bra 	BB3_14;

	shl.b64 	%rd67, %rd109, 3;
	add.s64 	%rd111, %rd1, %rd67;

BB3_13:
	ld.global.u64 	%rd68, [%rd111];
	add.s64 	%rd69, %rd68, %rd114;
	ld.global.u64 	%rd70, [%rd111+8];
	add.s64 	%rd71, %rd70, %rd69;
	ld.global.u64 	%rd72, [%rd111+16];
	add.s64 	%rd73, %rd72, %rd71;
	ld.global.u64 	%rd74, [%rd111+24];
	add.s64 	%rd114, %rd74, %rd73;
	add.s64 	%rd111, %rd111, 32;
	add.s64 	%rd109, %rd109, 4;
	setp.lt.s64	%p9, %rd109, %rd5;
	@%p9 bra 	BB3_13;

BB3_14:
	cvta.to.global.u64 	%rd75, %rd49;
	st.global.u64 	[%rd75], %rd114;

BB3_28:
	ret;
}


